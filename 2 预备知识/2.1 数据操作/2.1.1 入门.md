### 1.torch.arange的基本用法 ###
```python
torch.arange(start=0, end, step=1, dtype=None, device=None)
# 1.step：步长（默认为 1）
# 2.如果没有写start,就是从0开始
# 3.左闭右开
```

**只写 end： 用 torch.arange 生成 0 到 12的一维张量**
```python
x = torch.arange(13)
```

**写 start 和 end：用 torch.arange 生成 2 到 6的一维张量**
```python
tensor([2, 3, 4, 5, 6])
```

**写步长 step：用 torch.arange生成从 1 到 9，步长为 2的一维张量**

```
torch.arange(start=1, end=10, step=2)
```

### 2.torch.linspace的基本用法 ###
```python
torch.linspace(start, end, steps=100, dtype=None, device=None)
# 1.step：生成的点数（默认为 100）
# 2.左闭右闭
```

**生成 0~1 的 5 个等间隔点**
```python
torch.linspace(0, 1, 5) #结果是包括1的
```

**生成 −π 到 π 的 1000 个点，并且只显示前10个点**
```python
x = torch.linspace(-torch.pi, torch.pi, 1000)[:10]
```

### 3.torch.arange和torch.linspace的区别
<img width="901" height="543" alt="image" src="https://github.com/user-attachments/assets/7ae3ffdc-fdc5-40de-9038-5ad26f5b3ce4" />


### 4.张量的现状属性shape   (张量.shape)

在PyTorch 里：```x.shape``` 是 **张量的形状信息**，返回的是一个 **torch.Size 对象**，本质上可以当成**查看张量的维度长度**。并且x.shape   ==   x.size()

**查看三维张量的第1维，第2维，第3维的长度**
```python
import torch
x = torch.randn(2, 3, 4)
print(x.shape)
```
输出：
```python
torch.Size([2, 3, 4])
# 第 0 维：长度 2
# 第 1 维：长度 3 
# 第 2 维：长度 4
# 的2×3×4 的三维数组。
```

**查看一维张量（向量）的维度数和维度长度**
```python
import torch
x = torch.randn(5)
print(x.ndim)
print(x.shape)
```
**查看二维张量（矩阵）的第二维维度长度**
```python
import torch
x = torch.randn(3,4)
print(x.shape[1])
```
**查看四维张量的最后一维的维度长度和倒数第二维的维度长度**
```python
import torch
x = torch.randn(4,1,28,27) #(N, C, H, W)
print(x.shape[-1])
print(x.shape[-2])
```

**x.shape 和 x.size() 的关系**
**在 PyTorch 中：```x.shape   ==   x.size()```几乎完全等价。**
```python
x = torch.randn(2, 3, 4)

print(x.shape)      # torch.Size([2, 3, 4])
print(x.size())     # torch.Size([2, 3, 4])

print(x.size(0))    # 2  第 0 维长度
print(x.size(1))    # 3  第 1 维长度
print(x.size(2))    # 4  第 2 维长度
```

### 5.x.view的用法 ###
**在不改变数据内容的情况下，改变张量形状（shape）**
**其在应用时有一个大前提 ：x 必须是 连续内存 tensor,如果x不是连续内存要用 x.contiguous()将其转换成连续内存**
<img width="683" height="433" alt="image" src="https://github.com/user-attachments/assets/a8f371eb-e4a0-4326-b63b-5d344dbb009a" />

*将三维张量形状改成二维张量现状*
```python
import torch
x = torch.randn(2, 3, 4)
print(x.shape)   # torch.Size([2, 3, 4])

#利用x.view
x = x.view(2, 12)
print(x.shape)      # torch.Size([2, 12])

```

*利用x.view的自动推断展平为二维和一维*
```python

import torch
x = torch.randn(4, 3, 28, 28)
print(x.shape)   # torch.Size([4, 3, 28, 28])

#利用x.view的自动推断展平
x = x.view(4, -1)
print(x.shape)      # torch.Size([4, 2352])


x = torch.randn(2, 3, 4)
y = x.view(-1)
print(y.shape)      # torch.Size([24])


```
*利用x.view的自动推断展平指定维*

```python

import torch
x = torch.randn(8, 16, 7, 7)
x = x.view(x.shape[1], -1) #第二维不变
# 或者
# x = x.view(x.size(1),-1)
x.shape # torch.Size([16, 392])

```

### 和x.reshape的区别：
<img width="967" height="445" alt="image" src="https://github.com/user-attachments/assets/d1bc4108-4ae1-452b-9aee-703c7d8728e8" />

### transpose 后张量不再连续，所以使用x.reshape

### 6.x.reshape的用法 ###

### 改变张量的形状（shape）,不改变数据本身和总元素个数,
### 和 view() 类似，但更智能,和view 的关键区别是reshape() 不要求张量是连续内存

*基本用法*
``` python

import torch

x = torch.randn(2, 3, 4)
print(x.shape)          # torch.Size([2, 3, 4])

y = x.reshape(6, 4)
print(y.shape)          # torch.Size([6, 4])

```

*-1 让 PyTorch 自动推算*
*自动推算一维*
``` python

x = torch.randn(2, 3, 4)
y = x.reshape(-1)
print(y.shape)      # torch.Size([24])


```

*自动推算二维*
``` python

x = torch.randn(4, 3, 28, 28)
y = x.reshape(4, -1)
print(y.shape)      # torch.Size([4, 2352])

```

* 指定维度不写死（最推荐）*
``` python

x = torch.randn(8, 16, 7, 7)
y = x.reshape(x.shape[0], -1)

print(y.shape)      # torch.Size([8, 784])

```

### 7.x.unsqueeze的用法 ###

x.unsqueeze(dim) 是 PyTorch 里**加一个新维度并且新维度长度恒为 1**的操作

* 指定维度不写死（最推荐）*
``` python

import torch
x = torch.randn(3)
print(x.shape)   #torch.Size([3])

# 在第 0 维加一维长度为1的维度
y = x.unsqueeze(0)
print(y.shape)   #torch.Size([1,3])

# 在第 1 维加一维长度为1的维度
z = x.unsqueeze(1)
print(z.shape)   #torch.Size([3,1])


```

### 8.x.squeeze的用法 ###

x.squeeze() 是**删除所有 size(长度) 为 1 的维度**
x.squeeze(dim) 是 PyTorch 里**删除维度为1**的操作

*删除所有 size(长度) 为 1 的维度*
``` python

import torch
x = torch.randn(1, 3, 1, 4)
print(x.shape) # torch.Size([1, 3, 1, 4])

y = x.squeeze()
print(y.shape) # torch.Size([3, 4])

```

*删除维度为1的维度，如果维度的size不为1，则没有变化*

``` python
x = torch.randn(2, 3, 1)

x.squeeze(0).shape   # 第0维是2，不是1 → 不变
# torch.Size([2, 3, 1])

x.squeeze(2).shape   # 第2维是1 → 被去掉
# torch.Size([2, 3])

```
### 9.x.permute的用法 ###

permute 是**用0,1,2,3,...重新排列维度顺序**

*(2,3,4) -> (4,3,2)*

``` python
x = torch.randn(2,3,4)
x.shape   # torch.Size([2, 3, 4])

x = x.permute(2,1,0)
x.shape   # torch.Size([4, 3, 2])

```
