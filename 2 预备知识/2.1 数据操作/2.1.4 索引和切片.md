1.取一个3x3矩阵的主对角线元素

diag = x[range(3),range(3)]

2.取一个矩阵3x3的第二行

x[1,:]

3.取一个矩阵3x3的第 1~2 列

x[:,:2]

4.用布尔索引把一维张量中的负数置为0

x[x<0]=0

5.取所有 batch 的第 0 个通道，其中形状为(batch,channel,H,W) = torch.randn(32,3,28,28)

x[:,0,:,:].shape

6.利用切片索引插入指定的一维

x[:,None,:,:]

7.取所有 batch 的中心像素(B,C,H,W)

x[:,:,H//2,W//2]

8.删除第 1/2/3 维 (3,4,5) -> (4,5)

x[1] x[:,2:] x[:,:,3]

9. ( B , C , H , W ) -> ( B , H , W , C )

x.permute(0,2,3,2)

### 1.基本切片

*取前三个*
x[:3]

*取后两个*
x[-2:]

*取中间(左闭右开)*
x[1:4] #1,2,3

```python
import torch
x = torch.tensor([10, 20, 30, 40, 50])

#取前三个
x[:3]

*取后两个
x[:-2]

*取中间(左闭右开)*
x[1:4]

```

### 2.多维切片（矩阵/高维张量）

*取二维张量(矩阵)的第0行*
x[0]

*取二维张量(矩阵)的第1列*
x[:,1]

*取子矩阵(前两行前两列)*
x[:2,:2]


``` python
import torch
x = torch.tensor([[1,2,3],[4,5,6],[7,8,9])

#取二维张量(矩阵)的第0行
x[0]

#取二维张量(矩阵)的第1列
x[:,1]

#取子矩阵(前两行前两列)
x[:2,:2]
```
### 3.步长切片

*每隔2个取一个数*
x[::2]


*取 2~8 中的奇数*
x[3:9:2]

``` python
x = torch.arange(9)

#每隔2个取一个数
x[::2]

#倒序
x[::-1]

#取 2~8 中的奇数
x[3:9:2]
```

### 4.省略号 ...
在一维情况下（其实没啥用），

二维情况下：... = 自动补 :

在三维及以上：...的威力开始体现，哪一维填数字，那一维就(压缩)去掉维度

*前面维度都不变，取出最后一维 index=0*

```python

x = torch.randn(2, 3, 4, 5)

x[...,3].shape

# torch.Size([2, 3, 4])

```

*取出第一维=1 后面全部都不变*

```python

x = torch.randn(2, 3, 4, 5)

x[0,...].shape

#torch.Size([3, 4, 5]) 
```

*取出2,3维*

```python

x = torch.rand(2,3,4,5)

x[...,2,3].shape

# torch.Size([2, 3])
```

### 5.整数索引

按位置取指定元素

```python
x =  tensor([2,3,4,5])

x[2]

# tensor(4)

y = torch.arange(9).reshape(3,3)

y[1,2]

# tensor(5)

```


### 6.高级索引

用列表或者张量索引

*一维*
``` python
x = torch.tensor([10,20,30,40,50])
idx = torch.tensor([0,2,4])

x[idx]
# tensor([10, 30, 50])
```

*二维*
``` python
x = torch.arange(9).reshape(3,3)
rows = torch.tensor([0,2])
cols = torch.tensor([1,2])
x[rows,cols]
# tensor([1,8])
```


### 7.布尔索引(mask)

``` python
x = torch.tensor([1,-2,3,-4,5])

mask = x > 0

mask

# tensor([ True, False,  True, False,  True])

x[x>0]
# tensor([1, 3, 5])

x[x<0] = 0
x
#tensor([1,0,3,0,5])

```

